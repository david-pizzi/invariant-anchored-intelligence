# Invariants

## Definition

An **invariant** is an external reference that the system is **not allowed to redefine**
as truth, success, or improvement by itself.

Invariants are:
- not moral rules,
- not human values,
- not domain constraints.

They are **anchors for evaluation**.

---

## Why Invariants Matter

A self-improving system becomes uncorrectable when it gains authority to decide
what counts as “better” or “true” on its own.

Without invariants:
- evaluation becomes circular,
- failure can be redefined as success,
- oversight becomes interpretive rather than factual.

With at least one invariant:
- improvement remains measurable,
- correction remains possible,
- self-improvement remains grounded.

---

## Example Classes of Invariants

The project does not mandate a single invariant, but typical examples include:

- **Empirical reality**  
  Outcomes must correspond to observed results in the world.

- **External evaluation**  
  Success metrics are computed outside the system.

- **Causal consistency**  
  Improvements must preserve cause–effect relationships.

- **Resource conservation**  
  Solutions must respect hard limits (time, cost, capacity).

- **Auditability / reversibility**  
  Changes must be inspectable and, where possible, reversible.

---

## Rules for Invariants

- At least **one invariant must always remain active**.
- The system may **not unilaterally remove or redefine** an invariant.
- Invariants may change **only via external decision** (e.g. human-mediated).
- Multiple invariants may coexist, with one acting as a root anchor.

---

## What Invariants Do Not Do

Invariants do **not**:
- limit creativity,
- restrict internal representations,
- prevent radical problem reformulation,
- force human-style reasoning.

They only ensure that *improvement remains externally grounded*.
