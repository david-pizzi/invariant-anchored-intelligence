timestamp,run_id,generation,system,avg_regret,avg_reward,strain_detected,proposal_name,decision,decision_confidence,invariants
2026-01-15T11:48:48.330475,iai_evolution,0,iai,582.2620863495713,3697.0,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:48:58.593989,iai_evolution,1,iai,565.6501788454055,3607.6666666666665,True,regret_rate_penalty,MODIFY,0.7,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:49:02.561803,iai_evolution,2,iai,506.2961258815009,4422.0,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:49:11.626585,iai_evolution,3,iai,643.1015330589557,4589.333333333333,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:49:15.489507,iai_evolution,4,iai,505.984004773032,3902.6666666666665,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:49:19.384723,iai_evolution,5,iai,615.1483309689127,4325.333333333333,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:49:23.010771,iai_evolution,6,iai,342.195259980869,4441.666666666667,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:49:31.542520,iai_evolution,7,iai,922.8583919088,4555.333333333333,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:49:40.438999,iai_evolution,8,iai,626.7316802785767,4687.333333333333,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:49:48.758951,iai_evolution,9,iai,634.9849102876365,4048.0,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:51:21.032034,iai_evolution,0,iai,582.2620863495713,3697.0,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:51:30.946803,iai_evolution,1,iai,565.6501788454055,3607.6666666666665,True,regret_rate_penalty,MODIFY,0.85,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:51:34.941556,iai_evolution,2,iai,506.2961258815009,4422.0,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:51:44.094302,iai_evolution,3,iai,643.1015330589557,4589.333333333333,True,regret_rate_penalty,MODIFY,0.85,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:51:47.814225,iai_evolution,4,iai,505.984004773032,3902.6666666666665,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:56:01.950279,iai_evolution,0,iai,582.2620863495713,3697.0,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:56:11.724177,iai_evolution,1,iai,565.6501788454055,3607.6666666666665,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:56:15.629987,iai_evolution,2,iai,506.2961258815009,4422.0,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:56:24.086320,iai_evolution,3,iai,643.1015330589557,4589.333333333333,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:56:27.876184,iai_evolution,4,iai,505.984004773032,3902.6666666666665,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:56:31.730791,iai_evolution,5,iai,615.1483309689127,4325.333333333333,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:56:35.419319,iai_evolution,6,iai,342.195259980869,4441.666666666667,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:56:45.089638,iai_evolution,7,iai,922.8583919088,4555.333333333333,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:56:54.577623,iai_evolution,8,iai,626.7316802785767,4687.333333333333,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:57:02.984841,iai_evolution,9,iai,634.9849102876365,4048.0,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:59:25.009665,iai_evolution,0,iai,582.2620863495713,3697.0,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T11:59:34.622206,iai_evolution,1,iai,565.6501788454055,3607.6666666666665,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:59:38.479424,iai_evolution,2,iai,506.2961258815009,4422.0,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:59:48.240361,iai_evolution,3,iai,643.1015330589557,4589.333333333333,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T11:59:52.025195,iai_evolution,4,iai,505.984004773032,3902.6666666666665,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:07:14.737436,iai_evolution,0,iai,477.7142506609367,3943.0,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:07:19.520437,iai_evolution,1,iai,595.7921255878937,3633.2,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:07:24.089826,iai_evolution,2,iai,672.6496089812496,4142.6,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:07:34.065088,iai_evolution,3,iai,479.962687336728,4609.0,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:07:38.800155,iai_evolution,4,iai,614.8354578003969,4275.6,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:07:43.738838,iai_evolution,5,iai,701.7239611937027,3898.8,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:07:48.264674,iai_evolution,6,iai,502.2653974942379,3865.0,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:07:58.770923,iai_evolution,7,iai,969.9734860283672,4317.4,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:03.615445,iai_evolution,8,iai,696.5027125220452,4303.2,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:08.376122,iai_evolution,9,iai,446.42831431569846,4599.0,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:17.716658,iai_evolution,10,iai,530.6757136915814,3949.8,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:27.174255,iai_evolution,11,iai,707.3012056914708,4530.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:32.103221,iai_evolution,12,iai,891.1851943515348,4380.2,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:36.740003,iai_evolution,13,iai,590.0781285414841,4559.6,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:41.456282,iai_evolution,14,iai,154.5665735361368,4581.0,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:46.073418,iai_evolution,15,iai,580.7302224113693,4427.8,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:08:56.827208,iai_evolution,16,iai,786.0294314960893,3723.4,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:09:06.261678,iai_evolution,17,iai,681.1511952599071,4284.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:09:15.761853,iai_evolution,18,iai,1016.6926024243076,4145.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:09:20.797291,iai_evolution,19,iai,626.1703295850857,4660.6,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:13:09.747585,iai_evolution,0,iai,306.7653425840966,1827.3333333333333,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:13:12.903079,iai_evolution,1,iai,332.5005314322408,1815.3333333333333,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:13:16.078124,iai_evolution,2,iai,326.81521379124666,2014.3333333333333,False,,NO_REVIEW,,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:13:27.911358,iai_evolution,3,iai,438.6146556819262,2148.0,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:13:30.815150,iai_evolution,4,iai,295.8154920581589,2057.333333333333,False,,NO_REVIEW,,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:25:18.395705,iai_evolution,0,iai,306.7653425840966,1827.3333333333333,False,,REJECT,0.0,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:25:28.165513,iai_evolution,1,iai,332.5005314322408,1815.3333333333333,False,,REJECT,0.0,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:25:38.084276,iai_evolution,2,iai,326.81521379124666,2014.3333333333333,False,,REJECT,0.0,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:25:49.651535,iai_evolution,3,iai,438.6146556819262,2148.0,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:25:59.782355,iai_evolution,4,iai,295.8154920581589,2057.333333333333,False,,REJECT,0.0,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:26:50.584945,iai_evolution,0,iai,306.7653425840966,1827.3333333333333,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:26:59.439666,iai_evolution,1,iai,332.5005314322408,1815.3333333333333,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:27:08.292145,iai_evolution,2,iai,326.81521379124666,2014.3333333333333,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:27:20.033861,iai_evolution,3,iai,438.6146556819262,2148.0,True,regret_rate_penalty,MODIFY,0.85,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:27:29.341719,iai_evolution,4,iai,295.8154920581589,2057.333333333333,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:29:43.835539,iai_evolution,0,iai,477.7142506609367,3943.0,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:29:55.030837,iai_evolution,1,iai,595.7921255878937,3633.2,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:30:05.899418,iai_evolution,2,iai,672.6496089812496,4142.6,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:30:19.171774,iai_evolution,3,iai,479.962687336728,4609.0,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:30:30.239967,iai_evolution,4,iai,614.8354578003969,4275.6,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:30:41.484269,iai_evolution,5,iai,701.7239611937027,3898.8,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:30:52.630873,iai_evolution,6,iai,502.2653974942379,3865.0,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:31:06.006803,iai_evolution,7,iai,969.9734860283672,4317.4,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:31:17.108076,iai_evolution,8,iai,696.5027125220452,4303.2,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:31:28.382683,iai_evolution,9,iai,446.42831431569846,4599.0,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T12:33:58.643780,iai_evolution,0,iai,306.7653425840966,1827.3333333333333,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:34:07.738983,iai_evolution,1,iai,332.5005314322408,1815.3333333333333,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T12:34:20.319659,iai_evolution,2,iai,326.81521379124666,2014.3333333333333,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T13:56:09.318275,iai_evolution,0,iai,457.5372464239055,4216.7,True,regret_rate_penalty,MODIFY,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T13:56:26.407214,iai_evolution,1,iai,490.13303520196575,3911.2,True,regret_rate_penalty,MODIFY,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T13:56:40.640809,iai_evolution,2,iai,630.9378145625099,4392.2,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T13:56:56.262679,iai_evolution,3,iai,446.1424625090151,4512.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T13:57:10.261299,iai_evolution,4,iai,786.0844448817058,4417.5,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T13:57:26.290871,iai_evolution,5,iai,444.6743153930438,4257.5,True,reward_with_stability,ACCEPT,0.85,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-15T13:57:40.328279,iai_evolution,6,iai,426.4906056278441,4442.4,False,,NO_CHANGE,0.95,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-15T13:57:55.887796,iai_evolution,7,iai,796.1769921359509,4170.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T13:58:12.561537,iai_evolution,8,iai,657.1794516216447,4402.8,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T13:58:27.972655,iai_evolution,9,iai,566.4771370924851,4289.7,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:02:25.259288,iai_evolution,0,iai,68.861836267005,1232.5,True,reward_with_stability,ACCEPT,0.9,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-15T14:02:34.057886,iai_evolution,1,iai,82.01721875111727,1224.5,False,,NO_CHANGE,0.95,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-15T14:10:10.254814,iai_evolution,0,iai,457.5372464239055,4216.7,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:10:28.767585,iai_evolution,1,iai,490.13303520196575,3911.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:10:44.376784,iai_evolution,2,iai,630.9378145625099,4392.2,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:11:02.812856,iai_evolution,3,iai,446.1424625090151,4512.2,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:11:16.881112,iai_evolution,4,iai,786.0844448817058,4417.5,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:11:35.228950,iai_evolution,5,iai,444.6743153930438,4257.5,True,reward_with_stability,MODIFY,0.7,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:11:50.838402,iai_evolution,6,iai,426.4906056278441,4442.4,False,,NO_CHANGE,0.95,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:12:07.229053,iai_evolution,7,iai,796.1769921359509,4170.2,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:12:23.450704,iai_evolution,8,iai,657.1794516216447,4402.8,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T14:12:38.575025,iai_evolution,9,iai,566.4771370924851,4289.7,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T16:15:43.888895,iai_evolution,0,iai,85.87968133360074,2074.5,True,reward_with_stability,MODIFY,0.7,"{""metric"": ""cumulative_reward""}"
2026-01-15T16:15:53.511265,iai_evolution,1,iai,108.29648726964042,2046.5,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T16:16:02.530589,iai_evolution,2,iai,86.2989444412045,2322.0,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T16:23:56.178365,iai_evolution,0,iai,457.5372464239055,4216.7,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T16:24:10.978835,iai_evolution,1,iai,490.13303520196575,3911.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T16:24:27.829131,iai_evolution,2,iai,630.9378145625099,4392.2,True,baseline_relative_regret,ACCEPT,0.9,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.5x baseline (375.2), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T16:24:44.219061,iai_evolution,3,iai,446.1424625090151,4512.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T16:25:00.922983,iai_evolution,4,iai,786.0844448817058,4417.5,True,baseline_relative_regret,ACCEPT,0.9,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.5x baseline (375.2), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T16:25:16.634898,iai_evolution,5,iai,444.6743153930438,4257.5,True,reward_with_stability,MODIFY,0.85,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.5x baseline (375.2), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T16:25:30.119336,iai_evolution,6,iai,426.4906056278441,4442.4,False,,NO_CHANGE,0.95,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.5x baseline (375.2), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T16:25:45.585043,iai_evolution,7,iai,796.1769921359509,4170.2,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T16:26:00.592952,iai_evolution,8,iai,657.1794516216447,4402.8,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T16:26:16.922223,iai_evolution,9,iai,566.4771370924851,4289.7,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T16:38:44.731455,iai_evolution,0,iai,68.861836267005,1232.5,True,reward_with_stability,ACCEPT,0.85,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-15T16:38:54.944279,iai_evolution,1,iai,82.01721875111727,1224.5,True,baseline_relative_regret,MODIFY,0.9,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-15T16:42:49.758814,iai_evolution,0,iai,41.36298466175074,379.0,True,baseline_relative_regret,MODIFY,0.8,"{""metric"": ""cumulative_reward""}"
2026-01-15T16:43:00.150354,iai_evolution,1,iai,46.46314919132423,391.5,True,baseline_relative_regret,MODIFY,0.85,"{""metric"": ""cumulative_reward""}"
2026-01-15T17:01:18.813135,2026-01-15_170050,0,iai,41.36298466175074,379.0,True,baseline_relative_regret,ACCEPT,0.85,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.7x baseline (26.9), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T17:01:28.441051,2026-01-15_170050,1,iai,46.46314919132423,391.5,True,baseline_relative_regret,MODIFY,0.95,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.7x baseline (26.9), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T17:22:48.295632,2026-01-15_172221,0,iai,457.5372464239055,4216.7,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T17:23:03.868330,2026-01-15_172221,1,iai,490.13303520196575,3911.2,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T17:23:20.145676,2026-01-15_172221,2,iai,630.9378145625099,4392.2,True,baseline_relative_regret,MODIFY,0.7,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T17:23:35.745377,2026-01-15_172221,3,iai,446.1424625090151,4512.2,True,regret_rate_penalty,ACCEPT,0.9,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T17:23:52.666733,2026-01-15_172221,4,iai,786.0844448817058,4417.5,True,baseline_relative_regret,ACCEPT,0.9,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.5x baseline (375.2), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T17:24:08.588117,2026-01-15_172221,5,iai,444.6743153930438,4257.5,True,reward_with_stability,MODIFY,0.8,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.5x baseline (375.2), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T17:24:22.143953,2026-01-15_172221,6,iai,426.4906056278441,4442.4,False,,NO_CHANGE,0.95,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 1.5x baseline (375.2), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
2026-01-15T17:24:39.888291,2026-01-15_172221,7,iai,796.1769921359509,4170.2,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T17:24:54.863895,2026-01-15_172221,8,iai,657.1794516216447,4402.8,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T17:25:10.762009,2026-01-15_172221,9,iai,566.4771370924851,4289.7,True,regret_rate_penalty,ACCEPT,0.85,"{""metric"": ""regret_rate_penalty"", ""description"": ""Add penalty for increasing regret rate over time"", ""formula"": ""reward - lambda * max(0, d/dt[regret](t) - threshold)""}"
2026-01-15T22:17:10.548978,2026-01-15_221638,0,iai,94.08596884799596,2073.333333333333,True,reward_with_stability,ACCEPT,0.9,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-15T22:17:23.072381,2026-01-15_221638,1,iai,94.97159642654958,1911.3333333333333,True,baseline_relative_regret,MODIFY,0.95,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-15T22:31:53.086798,2026-01-15_223028,0,iai,94.08596884799596,2073.333333333333,True,reward_with_stability,REJECT,0.85,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:33:20.850617,2026-01-15_223028,1,iai,94.97159642654958,1911.3333333333333,True,baseline_relative_regret,REJECT,0.85,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:34:52.328624,2026-01-15_223028,2,iai,90.14233465942806,2485.6666666666665,True,baseline_relative_regret,REJECT,0.85,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:50:25.459312,2026-01-15_225004,0,iai,94.08596884799596,2073.333333333333,True,reward_with_stability,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:50:38.823682,2026-01-15_225004,1,iai,94.97159642654958,1911.3333333333333,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:50:54.202059,2026-01-15_225004,2,iai,90.14233465942806,2485.6666666666665,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:55:45.582871,2026-01-15_225520,0,iai,412.115329113657,4016.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:56:01.313439,2026-01-15_225520,1,iai,520.7516672556827,3658.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:56:16.042532,2026-01-15_225520,2,iai,493.0054929756856,4548.6,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:56:31.517155,2026-01-15_225520,3,iai,449.7146045310507,4808.8,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T22:56:45.718709,2026-01-15_225520,4,iai,553.715804776675,4050.0,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:09:32.810428,2026-01-15_230847,0,iai,412.115329113657,4016.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:09:50.115126,2026-01-15_230847,1,iai,520.7516672556827,3658.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:10:05.544242,2026-01-15_230847,2,iai,493.0054929756856,4548.6,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:10:20.142772,2026-01-15_230847,3,iai,449.7146045310507,4808.8,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:10:35.265404,2026-01-15_230847,4,iai,553.715804776675,4050.0,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:20:23.862489,2026-01-15_232000,0,iai,412.115329113657,4016.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:20:39.901626,2026-01-15_232000,1,iai,520.7516672556827,3658.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:20:55.606684,2026-01-15_232000,2,iai,493.0054929756856,4548.6,True,baseline_relative_regret,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:21:13.603005,2026-01-15_232000,3,iai,449.7146045310507,4808.8,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:21:28.975160,2026-01-15_232000,4,iai,553.715804776675,4050.0,True,baseline_relative_regret,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:28:09.983463,2026-01-15_232746,0,iai,412.115329113657,4016.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:28:24.975403,2026-01-15_232746,1,iai,520.7516672556827,3658.4,True,regret_rate_penalty,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:28:40.473096,2026-01-15_232746,2,iai,493.0054929756856,4548.6,True,baseline_relative_regret,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:28:56.775220,2026-01-15_232746,3,iai,449.7146045310507,4808.8,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:29:11.805775,2026-01-15_232746,4,iai,553.715804776675,4050.0,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:37:38.808278,2026-01-15_233711,0,iai,412.115329113657,4016.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:37:53.147267,2026-01-15_233711,1,iai,520.7516672556827,3658.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:38:09.905608,2026-01-15_233711,2,iai,493.0054929756856,4548.6,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:38:25.938054,2026-01-15_233711,3,iai,449.7146045310507,4808.8,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:38:41.298263,2026-01-15_233711,4,iai,553.715804776675,4050.0,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:40:25.783364,2026-01-15_234000,0,iai,412.115329113657,4016.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:40:45.790309,2026-01-15_234000,1,iai,520.7516672556827,3658.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:41:00.450929,2026-01-15_234000,2,iai,493.0054929756856,4548.6,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:41:16.753659,2026-01-15_234000,3,iai,449.7146045310507,4808.8,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:41:31.570211,2026-01-15_234000,4,iai,553.715804776675,4050.0,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:41:46.613050,2026-01-15_234000,5,iai,595.7191439087348,3917.2,True,reward_with_stability,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:41:58.914840,2026-01-15_234000,6,iai,526.0551128436601,3802.4,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:42:16.095554,2026-01-15_234000,7,iai,936.3570255710612,4168.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:42:33.049422,2026-01-15_234000,8,iai,532.5276143949302,4590.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:42:53.343654,2026-01-15_234000,9,iai,438.9365032788695,4525.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:48:15.340615,2026-01-15_234749,0,iai,412.115329113657,4016.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:48:32.227846,2026-01-15_234749,1,iai,520.7516672556827,3658.4,True,regret_rate_penalty,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:48:48.178961,2026-01-15_234749,2,iai,493.0054929756856,4548.6,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:49:05.374625,2026-01-15_234749,3,iai,449.7146045310507,4808.8,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:49:22.502980,2026-01-15_234749,4,iai,553.715804776675,4050.0,True,baseline_relative_regret,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:49:39.800497,2026-01-15_234749,5,iai,595.7191439087348,3917.2,True,reward_with_stability,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:49:52.009543,2026-01-15_234749,6,iai,526.0551128436601,3802.4,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:50:09.366543,2026-01-15_234749,7,iai,936.3570255710612,4168.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:50:27.831255,2026-01-15_234749,8,iai,532.5276143949302,4590.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-15T23:50:45.780326,2026-01-15_234749,9,iai,438.9365032788695,4525.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:01:40.050968,2026-01-16_080035,0,iai,412.115329113657,4016.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:02:01.275483,2026-01-16_080035,1,iai,520.7516672556827,3658.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:02:18.882629,2026-01-16_080035,2,iai,493.0054929756856,4548.6,True,baseline_relative_regret,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:02:37.729175,2026-01-16_080035,3,iai,449.7146045310507,4808.8,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:02:57.696972,2026-01-16_080035,4,iai,553.715804776675,4050.0,True,baseline_relative_regret,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:03:16.903761,2026-01-16_080035,5,iai,595.7191439087348,3917.2,True,reward_with_stability,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:03:31.644443,2026-01-16_080035,6,iai,526.0551128436601,3802.4,False,,NO_CHANGE,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:03:53.681769,2026-01-16_080035,7,iai,936.3570255710612,4168.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:04:15.915417,2026-01-16_080035,8,iai,532.5276143949302,4590.4,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:04:34.389765,2026-01-16_080035,9,iai,438.9365032788695,4525.0,True,regret_rate_penalty,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:08:10.624816,2026-01-16_080747,0,iai,85.87968133360074,2074.5,True,reward_with_stability,REJECT,0.9,"{""metric"": ""cumulative_reward""}"
2026-01-16T08:08:23.134500,2026-01-16_080747,1,iai,108.29648726964042,2046.5,True,baseline_relative_regret,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-16T10:05:32.293390,2026-01-16_100431,0,iai,85.87968133360074,2074.5,True,reward_with_stability,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-16T10:06:18.737541,2026-01-16_100431,1,iai,108.29648726964042,2046.5,True,baseline_relative_regret,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-16T10:09:25.952616,2026-01-16_100825,0,iai,85.87968133360074,2074.5,True,reward_with_stability,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-16T10:10:04.000022,2026-01-16_100825,1,iai,108.29648726964042,2046.5,True,baseline_relative_regret,REJECT,0.95,"{""metric"": ""cumulative_reward""}"
2026-01-16T10:21:35.895145,2026-01-16_101959,0,iai,85.87968133360074,2074.5,True,reward_with_stability,ACCEPT,0.85,"{""metric"": ""reward_with_stability"", ""description"": ""Weighted combination of reward and switching penalty"", ""formula"": ""alpha * reward - beta * switching_rate""}"
2026-01-16T10:23:04.761711,2026-01-16_101959,1,iai,108.29648726964042,2046.5,True,baseline_relative_regret,ACCEPT,0.85,"{""metric"": ""baseline_relative_regret"", ""description"": ""Regret is 2.2x baseline (38.6), consider fundamental approach change"", ""formula"": ""regret / baseline_regret <= threshold""}"
